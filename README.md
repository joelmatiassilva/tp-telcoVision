# TelcoVision - Churn Prediction (Producci√≥n)

Este proyecto implementa un pipeline de MLOps completo para la predicci√≥n de churn en una empresa de telecomunicaciones, cumpliendo con los est√°ndares de producci√≥n.

## üéØ Cumplimiento de Etapas del Proyecto

### Etapa 5: CI/CD con GitHub Actions
**Objetivo**: Automatizar la validaci√≥n y el entrenamiento del modelo.

Implementaci√≥n en `.github/workflows/ci.yaml` (Rama `main`):
1.  **Automatizaci√≥n**: Se dispara autom√°ticamente en cada `push` a la rama `main`.
2.  **Reproducibilidad**: Descarga los datos versionados con **DVC** desde DagsHub.
3.  **Entrenamiento**: Ejecuta el pipeline de DVC (`dvc repro`) que corre `src/train.py`.
4.  **Persistencia**: El modelo entrenado se registra autom√°ticamente en **MLflow (DagsHub)**. Esto es cr√≠tico para conectar con la siguiente etapa.
5.  **Reporte**: Publica m√©tricas de evaluaci√≥n en el resumen del Pull Request.

### Etapa 7: Producci√≥n (Despliegue)
**Objetivo**: Disponibilizar el modelo para consumo externo.

Implementaci√≥n en `.github/workflows/ci.yaml` (Rama `deploy`):
1.  **Separaci√≥n de Entornos**: El despliegue solo ocurre cuando se hace merge/push a la rama `deploy`.
2.  **Verificaci√≥n de Seguridad**: Antes de desplegar, el script `src/check_model.py` verifica que exista un modelo v√°lido en MLflow (`Production`). Si no existe, el despliegue se cancela para evitar errores.
3.  **Arquitectura Serverless con Docker**:
    *   Se utiliza **AWS Lambda** para escalar autom√°ticamente y reducir costos.
    *   Se empaqueta la aplicaci√≥n en una imagen **Docker** (basada en `public.ecr.aws/lambda/python:3.9`) para soportar el tama√±o de las dependencias de **PyCaret** (>250MB).
4.  **API**: Se expone el modelo mediante **FastAPI** (`src/app.py`) con un endpoint `/predict` documentado.

## üèó Arquitectura T√©cnica

### Stack Tecnol√≥gico
-   **Entrenamiento**: PyCaret (AutoML).
-   **Tracking & Registry**: MLflow + DagsHub.
-   **Versionado de Datos**: DVC (Data Version Control).
-   **M√©tricas**: Estrategia h√≠brida DVC + MLflow.
-   **API**: FastAPI + Mangum (adaptador serverless).
-   **Infraestructura**: AWS Lambda (Docker Image) + Amazon ECR.
-   **CI/CD**: GitHub Actions.

### Estrategia de M√©tricas (H√≠brida)

El proyecto utiliza **ambos** sistemas de m√©tricas para obtener lo mejor de cada uno:

1.  **DVC Metrics** (`outputs/metrics/metrics.json`):
    *   M√©tricas b√°sicas en formato JSON versionado.
    *   Visible en terminal con `dvc metrics show`.
    *   Mostrado autom√°ticamente en el resumen de GitHub Actions.
    *   Ideal para comparaciones r√°pidas entre ramas (`dvc metrics diff`).

2.  **MLflow**:
    *   M√©tricas detalladas + gr√°ficos (ROC, Confusion Matrix).
    *   Hist√≥rico completo de experimentos.
    *   Registro de modelos con versionado.
    *   Accesible v√≠a web en [DagsHub](https://dagshub.com/joelmatiassilva/tp-labMineriaDeDatos-telco/experiments).

### Flujo de Trabajo Recomendado
1.  **Desarrollo (`main`)**:
    *   Hacer cambios en c√≥digo o datos.
    *   `git push origin main` -> GitHub Actions entrena y valida el modelo.
    *   Verificar m√©tricas y que el modelo aparezca en MLflow.
2.  **Despliegue (`deploy`)**:
    *   Una vez validado `main`, hacer merge a `deploy`.
    *   `git push origin deploy` -> GitHub Actions verifica el modelo, construye la imagen Docker y actualiza AWS Lambda.

## üìÇ Estructura del Proyecto

```
telco_prod/
‚îú‚îÄ‚îÄ .github/workflows/  # CI/CD: Separado en jobs build (main) y deploy (deploy)
‚îú‚îÄ‚îÄ data/               # Datos gestionados por DVC
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ app.py          # API FastAPI (Entrypoint Lambda)
‚îÇ   ‚îú‚îÄ‚îÄ check_model.py  # Script de verificaci√≥n pre-deploy
‚îÇ   ‚îú‚îÄ‚îÄ train.py        # Script de entrenamiento
‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py     # Evaluaci√≥n y generaci√≥n de m√©tricas
‚îÇ   ‚îî‚îÄ‚îÄ data_prep.py    # Preparaci√≥n de datos
‚îú‚îÄ‚îÄ Dockerfile          # Definici√≥n de la imagen para Lambda
‚îú‚îÄ‚îÄ dvc.yaml            # Pipeline reproducible (Data Prep -> Train -> Eval)
‚îú‚îÄ‚îÄ params.yaml         # Hiperpar√°metros globales
‚îî‚îÄ‚îÄ requirements.txt    # Dependencias del proyecto
```

## ‚òÅÔ∏è Configuraci√≥n de Secretos

Para que el despliegue funcione, se requieren los siguientes secretos en GitHub:
*   `DAGSHUB_USER`, `DAGSHUB_TOKEN`: Acceso a datos y MLflow.
*   `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_REGION`: Credenciales AWS.
*   `ECR_REPOSITORY`: Nombre del repo ECR.
*   `LAMBDA_FUNCTION_NAME`: Nombre de la funci√≥n Lambda.
